# -*- coding: utf-8 -*-
"""Prediksi Churn Pelanggan pada Perusahaan Telekomunikasi Menggunakan Algoritma XGBOOST, DECISION TREE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A4kEJrETmPcweFGI_aXGZqKsCSXA6vuR

# **Prediksi Churn Pelanggan pada Perusahaan Telekomunikasi Menggunakan Algoritma XGBOOST, DECISION TREE, DAN RANDOM FORREST**

**Nasya Talitha**

**Muhammad Athar Awliya**

**Putri Layna Aulia**

Definisi masing-masing kolom

● Customerid: id dari customer

● Gender: gender dari customer

● Seniorcitizen: apakah merupakan senior citizen atau tidak

● Partner: apakah memiliki partner atau tidak

● Dependents: apakah memiliki tanggungan atau tidak seperti anak dll

● Tenure: tenure dari langganan customer

● PhoneService: apakah menggunakan layanan phone atau tidak

● MultipleLines: apakah menggunakan multiple lines atau tidak

● InternetService: Tipe dari internet service yang digunakan

● OnlineSecurity: apakah menggunakan fitur online security

● OnlineBackup: apakah menggunakan fitur online backup

● DeviceProtection: apakah menggunakan fitur device protection

● TechSupport: apakah menggunakan fitur tech support atau tidak

● StreamingTV: apakah menggunakan fitur streaming TV atau tidak

● StreamingMovies: apakah menggunakan fiture streaming film atau tidak

● Contract: tipe contract dari customer

● PaperlessBilling: apakah menggunakan fitur paperless billing atau tidak

● PaymentMethod: payment tipe yang digunakan oleh customer

● MonthlyCharges: total charges/biaya bulanan yang dibayarkan

● TotalCharges: total charges secara keseluruhan yang dibayarkan

● Churn: target variabel yang menunjukan bahwa customer churn atau tidak

# **Ekstraksi Data**
"""

# Download Dataset
!gdown 1IX_RSFp8QbZmULWTvAKZcNWsv3sKiQ6t

# Import library yang dibutuhkan
import pandas as pd


# Tampilkan semua kolom (agar tidak di-truncate)
pd.set_option('display.max_columns', None)
pd.set_option('display.float_format', '{:.6f}'.format)

# Ekstraksi data
raw_data = pd.read_csv('Telecom_Customers_Churn.csv')

# Tampilkan sampel data
raw_data.head()

"""# **EDA dan Preprocessing Sederhana**

# **Informasi Umum Data**
"""

# Periksa informasi umum pada data
raw_data.info()

"""# **Transformasi & Cleaning Data**

## **Melakukan Standarisasi Nama Kolom**
"""

# Mengubah nama kolom menjadi lower case
raw_data.columns = raw_data.columns.str.lower()

# Tampilkan hasilnya
raw_data.head()

"""## **Konversi Tipe Data**"""

# Periksa kolom Total Charges
raw_data[raw_data['totalcharges'].str.contains('[^0-9\.]', regex=True)]

import numpy as np

# Proses mengganti spasi menjadi null
raw_data['totalcharges'] = raw_data['totalcharges'].replace('\s+', np.nan, regex=True)

# Proses mengubah tipe data menjadi float
raw_data['totalcharges'] = raw_data['totalcharges'].astype('float')

# Ubah seniorcitizen menjadi tipe object
raw_data['seniorcitizen'] = raw_data['seniorcitizen'].astype('object')

# Menampilkan baris yang memiliki null pada totalcharges
raw_data[raw_data['totalcharges'].isna()]

# Periksa kembali
raw_data.info()

"""## **Handle Missing Values**"""

# Hitung mediannya
med_totalcharges = raw_data['totalcharges'].median()

# Melakukan imputasi (pengisian missing value)
raw_data['totalcharges'] = raw_data['totalcharges'].fillna(med_totalcharges)

# Re-Check info umum
raw_data.info()

"""## **Handle Duplicated Data**"""

raw_data.duplicated(subset = 'customerid').sum()

"""# **Exploratory Data Analysis**"""

import plotly.express as px

# Membuat dataframe untuk distribusi churn
churn_counts = raw_data['churn'].value_counts().reset_index()
churn_counts.columns = ['Churn', 'Count']

# Membuat plot menggunakan Plotly
fig = px.bar(churn_counts, x='Churn', y='Count',
             title='Distribusi Churn',
             labels={'Churn': 'Churn Status', 'Count': 'Jumlah Pelanggan'},
             color='Churn')

fig.show()

# Memilih kolom numerik
numeric_columns = raw_data.select_dtypes(include=['int64', 'float64'])

# Menampilkan statistik deskriptif untuk kolom numerik
numeric_columns.describe()

"""Di asumsikan bahwa nilai pada kolom tenure adalah jumlah bulan

## **Handling Outliers**
"""

df_numeric = raw_data.select_dtypes(include=['int64', 'float64'])  # Memilih kolom numerik

# Definisikan warna yang digunakan
color = ['#ff6d00', '#ff8500', '#ff9e00', '#240046', '#5a189a', '#9d4edd', '#18af9d']

# Loop untuk membuat box plot untuk setiap kolom numerik
for i in range(len(df_numeric.columns)):
    # Membuat box plot horizontal
    fig = px.box(
        df_numeric,
        x=df_numeric.columns[i],
        orientation='h',
        color_discrete_sequence=[color[i % len(color)]]
    )

    # Memperbarui layout dan menampilkan plot
    fig.update_layout(
        title=f'<b>Box Plot untuk {df_numeric.columns[i]}</b>',
        yaxis=dict(
            title='',
            showgrid=False,
            showline=False,
            showticklabels=False,
            zeroline=False,
        ),
        xaxis=dict(
            title='Total',
            showgrid=False,
            showline=True,
            showticklabels=True,
            zeroline=False,
        )
    )

    fig.show()

"""Dalam fitur numerik pada dataset ini tidak ada outlier

## **Hitung Data Kategorik**
"""

object_col = raw_data.select_dtypes(include = 'object').columns

for col in object_col:
    print(f"\033[1;33m{col}\033[0m\n{raw_data[col].unique()}\n")

raw_data = raw_data.replace('No internet service', 'No')
raw_data = raw_data.replace('No phone service', 'No')

for col in object_col:
    print(f"\033[1;33m{col}\033[0m\n{raw_data[col].unique()}\n")

for col in object_col:
    print(f"\033[1;33m{col}\033[0m\n")
    print(raw_data[col].value_counts(), '\n')

data_churn = raw_data[raw_data['churn'] == 'Yes'].reset_index(drop = True)

for col in object_col:
    print(f"\033[1;33m{col}\033[0m\n")
    print(data_churn[col].value_counts(), '\n')

"""# **Feature Engineering**"""

raw_data

# Menambahkan fitur baru tenure_range
def categorize_tenure(tenure):
    if tenure <= 12:
        return '0-12 bulan'
    elif tenure <= 24:
        return '13-24 bulan'
    elif tenure <= 36:
        return '25-36 bulan'
    elif tenure <= 48:
        return '37-48 bulan'
    else:
        return '49 bulan ke atas'

raw_data['tenure_range'] = raw_data['tenure'].apply(categorize_tenure)

"""*   Lama Berlangganan dalam Rentang (tenure_range)

fitur pada tenure ke dalam rentang waktu (misalnya, 0-12 bulan, 13-24 bulan, dsb.), dengan alasan untuk membantu model memahami risiko churn berdasarkan periode langganan pelanggan. Pelanggan baru atau yang baru saja berganti kontrak mungkin memiliki risiko churn yang lebih tinggi.

"""

# Menambahkan fitur baru tenure_monthly_charge_interaction
raw_data['tenure_monthly_charge_interaction'] = raw_data['tenure'] * raw_data['monthlycharges']

"""* Interaksi antara monthlycharges dan tenure (tenure_monthly_charge_interaction)


Fitur ini dapat menunjukkan bagaimana biaya bulanan berinteraksi dengan lama berlangganan untuk mempengaruhi churn, dengan alasan dapat menambahkan hubungakn yang komleks melalui fitur interaksi untuk meningkatkan kemampuan prediksi model.
"""

# Menampilkan hasil penambahan fitur
raw_data

"""# **Data Pre-processing**

## **Encoding**
"""

data = raw_data.copy()

data = data.drop(columns = ['customerid'])

data['partner'] = data['partner'].map({'Yes': 0, 'No': 1})
data['internetservice'] = data['internetservice'].map({'Fiber optic': 2, 'DSL': 1, 'No' : 0})

from sklearn.preprocessing import LabelEncoder

# Membuat objek LabelEncoder
label_encoder = LabelEncoder()

object_col = data.select_dtypes(include = 'object').columns

for col in object_col:
    data[col] = label_encoder.fit_transform(data[col])

data.head()

"""## **Korelasi**"""

import matplotlib.pyplot as plt
import seaborn as sns

#Menghitung matriks korelasi
correlation_matrix = data.corr()

# Membuat heatmap untuk matriks korelasi
plt.figure(figsize=(14, 10))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', square=True, cbar_kws={"shrink": .8})
plt.title('Matriks Korelasi untuk Semua Fitur Setelah Encoding', fontsize=16)
plt.show()

"""## **Fitur yang digunakan**

Berdasarkan heatmap korelasi di atas, ada beberapa fitur yang digunakan untuk proses selanjutnya yaitu :

berdasarkan korelasi signifikan dengan churn
* contract
* tenure
* tenure_range
* monthlycharges
* totalcharges
* techsupport
* onlinesecurity
* paperlessbilling
* dependents
* partner
* deviceprotection
* paymentmethod
* tenure_monthly_charge_interaction

Fitur yang Bisa Dipertimbangkan
* seniorcitizen - meskipun korelasi positif kecil, karena pelanggan senior sedikit lebih berisiko churn.
* streamingtv dan streamingmovies - meskipun korelasi sangat kecil dipertimbagkan karna dampak layanan hiburan terhadap churn.

fitur yang tidak digunakan
* gender
* phoneservice
* multiplelines
* internetservice
* tenure (karena sudah digantikan oleh tenure_range menghindari multikolinearitas)

## **Scalling Data**
"""

from sklearn.preprocessing import RobustScaler

# Misalkan data sudah diproses sebelumnya
data = data.copy()

# Inisialisasi objek RobustScaler
scaler = RobustScaler()

# Fit dan transform data pada dataframe
scaled_values = scaler.fit_transform(data)

# Membuat dataframe baru dengan data yang telah discaling
df_scaled = pd.DataFrame(scaled_values, columns=data.columns)

# Tampilkan data yang telah discaling
df_scaled.head()

"""## **Data Split**"""

# Import library untuk splitting data
from sklearn.model_selection import train_test_split

# Definisikan fitur dan target
X = df_scaled.drop(columns=['churn', 'gender', 'phoneservice', 'multiplelines', 'internetservice', 'tenure'])
y = df_scaled['churn']

# Proses splitting data
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,   # 20% data untuk pengujian
    random_state=42  # Untuk reprodusibilitas
)

# Periksa banyak data masing-masing
print(f'Banyak data latih = {X_train.shape[0]}')
print(f'Banyak data test  = {X_test.shape[0]}')

X.columns

X.shape

X_train.shape

"""## **Handling Imbalanced Dataset**"""

y_train.value_counts()

from imblearn.over_sampling import SMOTE

# Menggunakan SMOTE untuk oversampling kelas minoritas
smote = SMOTE(random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

y_train.value_counts()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.model_selection import cross_validate

def eval_classification(model):

    # Prediksi pada data uji
    y_pred = model.predict(X_test)
    y_pred_train = model.predict(X_train)
    y_pred_proba = model.predict_proba(X_test)
    y_pred_proba_train = model.predict_proba(X_train)


    # Menampilkan metrik evaluasi
    print("Accuracy (Train Set): %.2f" % accuracy_score(y_train, y_pred_train))
    print("Accuracy (Test Set): %.2f" % accuracy_score(y_test, y_pred))

    print("Precision (Test Set): %.2f" % precision_score(y_test, y_pred))
    print("Recall (Test Set): %.2f" % recall_score(y_test, y_pred))
    print("F1-Score (Test Set): %.2f" % f1_score(y_test, y_pred))

    print("ROC AUC (Train Set): %.2f" % roc_auc_score(y_train, y_pred_proba_train[:, 1]))
    print("ROC AUC (Test Set): %.2f" % roc_auc_score(y_test, y_pred_proba[:, 1]))


    try:
        # Menggunakan cross-validation untuk recall
        score = cross_validate(model, X, y, cv=5, scoring='recall', return_train_score=True)
        print('Recall (Crossval Train): %.2f' % score['train_score'].mean())
        print('Recall (Crossval Test): %.2f' % score['test_score'].mean())
    except Exception as e:
        print(f"Skipped cross-validation due to error: {e}")

"""## **Fitting Model** (Decision Tree)"""

# Importing libraries
from sklearn.tree import DecisionTreeClassifier

# Membuat model Decision Tree
dt_model = DecisionTreeClassifier(max_leaf_nodes = 5)

# Melatih model dengan data latih
dt_model.fit(X_train, y_train)

from sklearn import tree
import matplotlib.pyplot as plt

# Membuat plot pohon keputusan
fig, ax = plt.subplots(figsize=(12, 12))
tree.plot_tree(
    dt_model,
    feature_names = dt_model.feature_names_in_,
    class_names = ['Stayed', 'Churn'],
    filled=True
)

plt.show()

"""### **Evaluation**"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Prediksi dengan data uji
y_pred = dt_model.predict(X_test)

# Evaluasi model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Menampilkan classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

eval_classification(dt_model)

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Menghitung confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Menampilkan confusion matrix menggunakan seaborn heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Stayed', 'Churn'], yticklabels=['Stayed', 'Churn'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""### **HyperParameter Tunning**

### Model Decision Tree
"""

from sklearn.model_selection import GridSearchCV

# Menentukan grid hyperparameter untuk pencarian
param_grid = {
    'max_depth': [None, 5, 10, 20, 50],  # Kedalaman pohon
    'min_samples_split': [2, 5, 10],  # Minimum sampel untuk membagi node
    'min_samples_leaf': [1, 2, 5],    # Minimum sampel pada daun
    'criterion': ['gini', 'entropy'] # Kriteria pemisahan
}

# Menggunakan GridSearchCV untuk mencari hyperparameter terbaik
grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Melatih model dengan pencarian hyperparameter
grid_search.fit(X_train, y_train)

# Menampilkan hasil pencarian terbaik
print("Best Hyperparameters:", grid_search.best_params_)

# Menggunakan model dengan hyperparameter terbaik untuk prediksi
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

# Evaluasi hasil
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy of the best model: {accuracy * 100:.2f}%")

# Menampilkan classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

eval_classification(best_model)

"""###**Feature Importance**"""

# Import library untuk visualisasi
import plotly.express as px

# Retrieve feature importances
feature_names = dt_model.feature_names_in_
importances = dt_model.feature_importances_

# Create a DataFrame with feature names and importances
df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})

# Sort the DataFrame by importance in descending order
df = df.sort_values('Importance', ascending=True)

# Create a bar plot using Plotly Express
fig = px.bar(df, y='Feature', x='Importance', title='Feature Importances', orientation = 'h')

fig.update_layout(
    width = 1200,
    height = 600,
    showlegend = False,
    margin = dict(l=160, r=200, t=100, b=30),
    plot_bgcolor = 'rgba(0, 0, 0, 0)',
    title = dict(
        text = "<b>Feature Importance</b>",
        font = dict(
            size = 23,
            color = '#757882'
        ),
        y = 0.92
    ),
    yaxis = dict(
        title = '',
        showgrid = True,
        showline = True,
        zeroline = False,
        gridcolor='lightgray',
    ),
    xaxis = dict(
        showgrid = True,
        showline = True,
    ),
)

fig.show()

"""## **Fitting Model** (XGBoost)"""

# Importing libraries
import xgboost as xgb

# Membuat model XGBoost
xgb_clf = xgb.XGBClassifier()
# Melatih model dengan data latih
xgb_clf.fit(X_train, y_train)

# Memprediksi hasil model
y_pred = xgb_clf.predict(X_test)

"""### **Evaluation**"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Prediksi dengan data uji
y_pred = xgb_clf.predict(X_test)

# Evaluasi model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Menampilkan classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Menghitung confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Menampilkan confusion matrix menggunakan seaborn heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Stayed', 'Churn'], yticklabels=['Stayed', 'Churn'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""### **HyperParameter Tunning**

### Model Decision Tree
"""

import xgboost as xgb
from sklearn.metrics import accuracy_score

# Pilih kombinasi hyperparameter terbaik secara langsung
params = {
    'n_estimators': 100,  # Pilihan dari param_grid['n_estimators']
    'max_depth': 5,       # Pilihan dari param_grid['max_depth']
    'learning_rate': 0.1, # Pilihan dari param_grid['learning_rate']
    'subsample': 0.8,     # Pilihan dari param_grid['subsample']
    'colsample_bytree': 1.0, # Pilihan dari param_grid['colsample_bytree']
    'objective': 'binary:logistic',
    'eval_metric': 'logloss',
}

# Melatih model dengan hyperparameter yang dipilih
xgb_clf = xgb.XGBClassifier(**params)
xgb_clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)

# Evaluasi model
y_pred = xgb_clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Akurasi Model: {accuracy * 100:.2f}%")

# Menampilkan classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

eval_classification(xgb_clf)

"""###**Feature Importance**"""

# Import library untuk visualisasi
import plotly.express as px

# Retrieve feature importances
feature_names = xgb_clf.feature_names_in_
importances = xgb_clf.feature_importances_

# Create a DataFrame with feature names and importances
df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})

# Sort the DataFrame by importance in descending order
df = df.sort_values('Importance', ascending=True)

# Create a bar plot using Plotly Express
fig = px.bar(df, y='Feature', x='Importance', title='Feature Importances', orientation = 'h')

fig.update_layout(
    width = 1200,
    height = 600,
    showlegend = False,
    margin = dict(l=160, r=200, t=100, b=30),
    plot_bgcolor = 'rgba(0, 0, 0, 0)',
    title = dict(
        text = "<b>Feature Importance</b>",
        font = dict(
            size = 23,
            color = '#757882'
        ),
        y = 0.92
    ),
    yaxis = dict(
        title = '',
        showgrid = True,
        showline = True,
        zeroline = False,
        gridcolor='lightgray',
    ),
    xaxis = dict(
        showgrid = True,
        showline = True,
    ),
)

fig.show()

"""## **Fitting Model (Random Forest)**"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

"""### **Evaluation**"""

eval_classification(rf)

"""Overfitting : Model mengalami overfitting, ditunjukkan oleh akurasi tinggi pada data pelatihan dan rendah pada data pengujian/validasi.

Kinerja Model : Meskipun model memberikan skor ROC AUC yang baik, precision dan recall yang relatif rendah, serta f1-score yang tidak begitu menggembirakan, menunjukkan bahwa model tidak cukup baik dalam memprediksi churn dengan baik.

### **HyperParameter Tunning**
"""

# tuning hyperparameter RF + oversampling
from sklearn.model_selection import RandomizedSearchCV

# Definisikan rentang hyperparameter
n_estimators = [int(x) for x in np.linspace(1, 200, 50)]
criterion = ['gini', 'entropy']
max_depth = [int(x) for x in np.linspace(2, 100, 50)]
min_samples_split = [int(x) for x in np.linspace(2, 20, 10)]
min_samples_leaf = [int(x) for x in np.linspace(1, 20, 10)]

hyperparameters = dict(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth,
                       min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf)

rf = RandomForestClassifier(random_state=42)
rs = RandomizedSearchCV(rf, hyperparameters, scoring='roc_auc', random_state=1, cv=5)
rs.fit(X_train, y_train)
eval_classification(rs)

"""

Performa : Meskipun banyak metrik menunjukkan performa yang baik, model mengalami overfitting, terlihat dari perbedaan signifikan antara nilai pada data latih dan uji.

Tuning dan Validasi : Metrik recall yang rendah menunjukkan bahwa model tidak cukup baik dalam menangkap pelanggan yang churn.
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

# Definisikan parameter yang ingin diuji
param_values = [int(x) for x in np.linspace(2, 50, 15)]  # Parameter yang akan diuji

train_scores = []
test_scores = []

for param in param_values:
    # Buat model dengan parameter yang diuji
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=None,  # Tidak dibatasi
        min_samples_split=2,  # Default
        min_samples_leaf=param,  # Parameter yang diuji
        random_state=42
    )
    model.fit(X_train, y_train)

    # Evaluasi pada train set
    y_pred_train_proba = model.predict_proba(X_train)
    train_auc = roc_auc_score(y_train, y_pred_train_proba[:, 1])
    train_scores.append(train_auc)

    # Evaluasi pada test set
    y_pred_proba = model.predict_proba(X_test)
    test_auc = roc_auc_score(y_test, y_pred_proba[:, 1])
    test_scores.append(test_auc)

    # Output hasil per iterasi
    print(f'Parameter value: {param}, Train AUC: {train_auc:.3f}, Test AUC: {test_auc:.3f}')

# Plot hasil learning curve
plt.figure(figsize=(10, 6))
plt.plot(param_values, train_scores, label='Train ROC AUC', marker='o')
plt.plot(param_values, test_scores, label='Test ROC AUC', marker='o')
plt.xlabel('Parameter Value')
plt.ylabel('ROC AUC Score')
plt.title('Learning Curve for Random Forest')
plt.legend()
plt.grid()
plt.show()

"""*   Train AUC - Skor AUC pada data latih mencapai hampir 1.00 saat min_samples_leaf rendah, tetapi menurun seiring bertambahnya nilai parameter.
*   Test AUC - Skor AUC Stagnan pada data uji relatif stabil sekitar pada 0.86 seiring dengan perubahan parameter.

Masih adanya Overfitting antara skor AUC untuk data train (tinggi) dan data test (lebih rendah).

**Menunjukan nilai optimal pada min_samples_leaf ke 15**
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score

# Model final dengan parameter optimal
final_model = RandomForestClassifier(
    n_estimators=50,  # Bisa menggunakan nilai terbaik dari eksplorasi lain
    max_depth=None,  # Jika diperlukan, bisa eksplorasi max_depth namun kami tidak menggunakan
    min_samples_split=2,  # Tetap default
    min_samples_leaf=15,  # Nilai optimal dari learning curve
    random_state=42
)

# Fit model dengan data
final_model.fit(X_train, y_train)

# Evaluasi pada train set
y_pred_train_proba = final_model.predict_proba(X_train)[:, 1]
train_auc = roc_auc_score(y_train, y_pred_train_proba)

# Evaluasi pada test set
y_pred_test_proba = final_model.predict_proba(X_test)[:, 1]
test_auc = roc_auc_score(y_test, y_pred_test_proba)

# Laporan hasil
print(f"Train ROC AUC: {train_auc:.3f}")
print(f"Test ROC AUC: {test_auc:.3f}")
print(classification_report(y_test, final_model.predict(X_test)))

"""*   Performa Baik tetapi Perlu Perbaikan : Model menunjukkan performa yang baik dengan AUC yang memuaskan, tetapi recall untuk kelas churn masih perlu ditingkatkan.
*   Overfitting : Perbedaan antara AUC di data latih dan uji menunjukkan bahwa model mungkin mengalami overfitting.

**Tingkatkan Recall Kelas Churn melalui pengaturan threshold**


"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Menghitung prediksi pada data uji
y_pred = final_model.predict(X_test)

# Membuat confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Membuat plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Tidak Churn (0)', 'Churn (1)'],
            yticklabels=['Tidak Churn (0)', 'Churn (1)'])

plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()

"""* True Positives (TP) :
280 : Jumlah pelanggan yang benar-benar churn dan diprediksi churn oleh model. Ini adalah prediksi yang benar dan menunjukkan efektivitas model dalam menangkap pelanggan berisiko churn.
*  True Negatives (TN) :
816 : Jumlah pelanggan yang tidak churn dan diprediksi sebagai tidak churn. Ini menunjukkan bahwa model dengan baik dalam mengidentifikasi pelanggan yang tetap berlangganan.
*  False Positives (FP) :
220 : Jumlah pelanggan yang sebenarnya tidak churn tetapi diprediksi sebagai churn. Model mengalami kesalahan di sini, dan ini dapat mengarah pada upaya retention yang tidak perlu.
*  False Negatives (FN) :
93 : Jumlah pelanggan yang sebenarnya churn tetapi diprediksi sebagai tidak churn. Ini adalah kesalahan penting karena pelanggan yang sebenarnya berisiko meninggalkan layanan tidak terdeteksi, yang dapat mengakibatkan hilangnya pendapatan.

###**Feature Importance**
"""

import pandas as pd
import matplotlib.pyplot as plt

def show_feature_importance(model, feature_names):
    # Dapatkan importance dari fitur
    importance = model.feature_importances_

    # Buat DataFrame untuk menampilkan hasil dengan lebih rapi
    feature_importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': importance
    })

    # Urutkan fitur berdasarkan tingkat kepentingannya
    # Visualisasikan dalam bentuk bar plot
    plt.figure(figsize=(10, 6))
    plt.barh(feature_importance_df.sort_values(by='Importance', ascending=False)['Feature'], feature_importance_df.sort_values(by='Importance', ascending=False)['Importance'], color='skyblue')
    plt.gca().invert_yaxis()  # Membalik urutan agar fitur terpenting ada di atas
    plt.xlabel('Feature Importance')
    plt.title('Feature Importance from Random Forest')
    plt.show()

    return feature_importance_df.sort_values(by='Importance', ascending=False)

# Asumsikan dalam estimator terbaik dari RandomizedSearchCV
best_rf_model = rs.best_estimator_

# Daftar nama fitur (jika tidak diketahui, gunakan X.columns untuk mengambil nama dari data training)
feature_names = X_train.columns

feature_importance_df = show_feature_importance(best_rf_model, feature_names)

"""### **Pengaturan Threshold**"""

from sklearn.metrics import precision_recall_curve, roc_auc_score, classification_report
import numpy as np

# Mendapatkan probabilitas prediksi
y_pred_proba = final_model.predict_proba(X_test)[:, 1]
thresholds = np.arange(0.1, 0.9, 0.1)

# Menampilkan hasil untuk setiap threshold
for threshold in thresholds:
    y_pred_adjusted = (y_pred_proba >= threshold).astype(int)

    # Evaluasi model pada threshold tersebut
    print(f"Threshold: {threshold:.2f}")
    print(classification_report(y_test, y_pred_adjusted))

    # Hitung ROC AUC untuk test set
    test_auc = roc_auc_score(y_test, y_pred_proba)
    # Hitung ROC AUC untuk train set
    y_train_proba = final_model.predict_proba(X_train)[:, 1]
    train_auc = roc_auc_score(y_train, y_train_proba)

    print(f"Train ROC AUC: {train_auc:.3f}")
    print(f"Test ROC AUC: {test_auc:.3f}\n")

"""Dengan pengaturan threshold ini ada beberapa hal yang perlu diperhatikan:


*   Menjaga Keseimbangan : Memilih threshold rendah sebagai contoh (0.1, 0.2) meningkatkan recall tetapi mengorbankan precision. Sebaliknya, threshold yang lebih tinggi mengurangi kemampuan mendeteksi churn (recall) tetapi meningkatkan precision.
*  Tujuan Bisnis :
Jika tujuan utama adalah meminimalkan kehilangan pelanggan, maka fokus pada recall yang tinggi lebih penting. Dalam hal ini, threshold yang lebih rendah (seperti 0.30 atau 0.40) lebih sesuai untuk menangkap sebanyak mungkin pelanggan yang berisiko churn, meskipun menghasilkan lebih banyak false positives.
* Keseimbangan Precision dan Recall :
Threshold sekitar 0.40 hingga 0.50 sering kali memberikan keseimbangan yang baik antara precision dan recall.

* Biaya dan Manfaat :
Pertimbangkan biaya yang terkait dengan mempertahankan pelanggan yang tidak akan churn (false positives). Jika biaya retention terlalu tinggi, threshold lebih tinggi bisa jadi lebih baik.
Pertimbangkan juga nilai dari pelanggan yang berhasil dipertahankan. Pastikan bahwa manfaat dari mempertahankan pelanggan yang dihargai lebih tinggi daripada biaya dari tindakan retention.

# **Evaluasi Model Terbaik dan Rekomendasi Bisnis**

Sebelum memilih kami akan coba evaluasi kembali hasil dari tiga model yang sudah di bentuk :

**1. Decision Tree**


*   Recall
 * Test Set: 91% untuk kelas positif (churn).
 * Cross-validation menunjukkan performa yang tidak konsisten dengan Recall sebesar 37% (train) dan 36% (test).

* ROC-AUC:
 * Train Set: 81%.
 * Test Set: 81%.

* Hasil Evaluasi Model :
Decision Tree menunjukkan kemampuan yang baik dalam mendeteksi pelanggan churn dengan Recall tinggi. Namun, performa ROC-AUC berada di bawah model lainnya, menandakan model ini kurang optimal dalam membedakan antara kelas churn dan non-churn.
Selain itu, performa yang tidak stabil dalam validasi silang menurunkan keandalan model ini.

**2. XGBoost**
* Recall:
  * Test Set: 70% untuk kelas positif (churn).
* ROC-AUC:
  * Train Set: 95%.
  * Test Set: 85%.
* Analisis:
XGBoost memiliki performa yang solid dengan ROC-AUC sebesar 85%, tetapi Recall lebih rendah dibandingkan Random Forest dan Decision Tree.
Perbedaan signifikan antara ROC-AUC train (95%) dan test (85%) menunjukkan potensi overfitting, yang dapat membatasi generalisasi model ini.


**3. Random Forest**

* Recall:
 * Test Set: 87% untuk kelas positif (churn).
 * Dengan threshold yang disesuaikan (0.40).

* ROC-AUC:
 * Train Set: 92.7%.
 * Test Set: 85.5%.

* Analisis:
Random Forest memberikan hasil terbaik pada metrik Recall (87%), yang berarti model ini sangat efektif dalam mengidentifikasi pelanggan churn setelah penyesuaian treshold.
ROC-AUC yang tinggi pada Train Set (92.7%) dan Test Set (85.5%) yang mengindikasikan bahwa model ini tidak mengalami overfitting secara signifikan dan memiliki kemampuan generalisasi yang baik

## **Model Akhir**

Dengan mempertimbangkan hasil dari metrics Recall dan ROC AUC
**Model Random Forest** di pilih sebagai model akhir untuk memprediksi churn karena alasan berikut:

* Recall yang tinggi (87%) menunjukkan bahwa model ini sangat baik dalam mendeteksi pelanggan churn, yang penting dalam konteks bisnis untuk mengidentifikasi pelanggan yang berisiko keluar dan bisa ditindaklanjuti dengan tindakan pencegahan.

* ROC-AUC yang stabil (85.5% pada Test Set) menandakan bahwa model ini memiliki kemampuan yang sangat baik dalam membedakan antara pelanggan yang akan churn dan yang tidak, dengan potensi overfitting yang rendah.

* Penyesuaian threshold meningkatkan sensitivitas model terhadap churn tanpa mengorbankan terlalu banyak prediksi yang salah, yang memberikan hasil yang lebih baik untuk pengambilan keputusan bisnis.

* Meskipun XGBoost menunjukkan ROC-AUC yang tinggi, masalah overfitting dan Recall yang lebih rendah dibandingkan dengan Random Forest menjadikannya kurang stabil. Decision Tree memiliki Recall yang tinggi, namun masalah konsistensi dan ROC-AUC rendah membuatnya kurang optimal dibandingkan dengan Random Forest.

## **Rekomendasi Bisnis**

Rekomendasi Bisnis Berdasarkan Evaluasi Model Akhir dan Feature Importance Model Random Forest :

**1. Optimalkan Intervensi pada Pelanggan dengan Risiko Churn Tinggi**

Dengan nilai Recall 87%
 * Pelanggan dengan kontrak bulanan (contract) dan tagihan bulanan tinggi (monthly charges) adalah target utama berdasarkan fitur importance.
 * Strategi seperti pemberian diskon atau konversi ke kontrak tahunan dapat mengurangi churn.
 * Pastikan sumber daya fokus pada pelanggan yang benar-benar terdeteksi churn (mempertahankan false positive seminimal mungkin).

**2. Kembangkan Program Loyalitas Berdasarkan Tenure**

 * Pelanggan dengan tenure singkat (tenure range) memerlukan perhatian khusus.
 * Program onboarding yang efektif dan penawaran personal dapat meningkatkan pengalaman pelanggan dan memperpanjang masa langganan.

**3. Tingkatkan Layanan Tambahan**

 * Layanan seperti online security, tech support, dan streaming services (movies & TV) memberikan nilai tambah yang memengaruhi churn.
 * Promosikan layanan ini secara proaktif, terutama kepada pelanggan yang menunjukkan tanda-tanda churn.

**4. Lakukan Pemantauan dan Penyesuaian Threshold**

 * Threshold 0.40 memberikan keseimbangan antara recall dan precision. Namun, lakukan evaluasi berkala untuk menyesuaikan threshold sesuai perubahan pola pelanggan.

**5. Perbaikan Berkelanjutan pada Model**
 * Meskipun hasil menunjukkan performa model yang baik, integrasikan data pelanggan terbaru untuk terus meningkatkan akurasi model prediksi.
"""

